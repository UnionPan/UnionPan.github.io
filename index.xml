<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>union&#39;s blog</title>
    <link>https://unionpan.github.io/</link>
    <description>Recent content on union&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Feb 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://unionpan.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Variational Perspective On Gradient Descent</title>
      <link>https://unionpan.github.io/post/variational_perspective/</link>
      <pubDate>Sun, 11 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://unionpan.github.io/post/variational_perspective/</guid>
      <description>In this post I just want to share a simple and elegant idea from a Control System Letter paper written by Maxim Raginsky et al.1. This idea largely inspired my recent work on multi-agent learning in (monotone) games2, which I might devote another post to talk about if I happen to get some interesting results out of it.&#xA;The idea starts from here: we all know that the archetype of solving convex optimization problem is through gradient descent: $$ x_{k+1} = x_k - \nabla f(x_k), $$ which, in continuous time, corresponds to an autonomous dynamical system: $$ \dot{x} = - \nabla f (x) , \quad x(0) = x_0.</description>
    </item>
    <item>
      <title> Some Notes on Dueling Bandits</title>
      <link>https://unionpan.github.io/post/dueling_bandits/</link>
      <pubDate>Wed, 11 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://unionpan.github.io/post/dueling_bandits/</guid>
      <description>The dueling bandit problem natrually fits the description of a variety of recommendation systems that require &amp;lsquo;&amp;rsquo;learning on the fly&amp;rsquo;&amp;rsquo;, yet have no explicit access to a &amp;lsquo;&amp;lsquo;reward&amp;rsquo;&amp;rsquo; model. Instead, the &amp;lsquo;&amp;lsquo;human&amp;rsquo;&amp;rsquo; feedback part takes the form of &amp;lsquo;&amp;lsquo;choices&amp;rsquo;&amp;rsquo;, &amp;lsquo;&amp;lsquo;votes&amp;rsquo;&amp;rsquo;, or some discrete forms. Hence, oftentimes a learning protocol proceeds at time steps \(t = 1, \ldots, T\):&#xA;The algorithm chooses a pair of arms \( a_i, a_j \) from \(K\) available ones; The oracle/human feedback/nature reveals the winner arm \( a_i \), with probability \( P(a_i \succ a_j)\), \( P(a_i \prec a_j) = 1 - P(a_i \succ a_j) \) So the feedback is either \(a_i\) or \( a_j \), the preferences forms a matrix \(P \in \mathbb{R}^{K \times K}\) such that \( P + P^{\top} = I\) which defines the hidden information of the dueling bandit problem.</description>
    </item>
    <item>
      <title>Wardrop Equilibrium</title>
      <link>https://unionpan.github.io/post/wardrop_equilibirum/</link>
      <pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://unionpan.github.io/post/wardrop_equilibirum/</guid>
      <description>I remember having those unpleasant lines in our high school canteen, flooded by the starving students queeing for their lunch, I would always pick a window with fewer people waiting, compromising myself with awful food. Another similar thought that always stricked me was the odds that tourists always pick the same time to travel, there&amp;rsquo;s almost always traffic congestion everywhere during holiday seasons. Yeah, lives have been always so hard.</description>
    </item>
    <item>
      <title>A Cryptographic Conundrum</title>
      <link>https://unionpan.github.io/post/the_capacity_of_deception/</link>
      <pubDate>Wed, 16 Nov 2022 18:58:11 +0800</pubDate>
      <guid>https://unionpan.github.io/post/the_capacity_of_deception/</guid>
      <description>The Quest for Optimal Communication Let there be Alice and Bob, whose mission this time is to navigate the labyrinth of random outcomes and communicate in the most efficient way possible.&#xA;Alice wants to communicate with Bob about a sequence of \(n\) independent random outcomes sampled from a known distribution \(Q\). To keep things concise, they&amp;rsquo;ve agreed on a secret binary language. Now, the plot thickens with the concept of entropy.</description>
    </item>
    <item>
      <title>Nesterov</title>
      <link>https://unionpan.github.io/post/nesterov/</link>
      <pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://unionpan.github.io/post/nesterov/</guid>
      <description>We briefly reviewed the lower complexity bound of first-order convex optimization and how Nesterov proceed to match the lower bound using the estimation sequence, the slides are here.&#xA;Consider an unconstrained optimization problem: \[ \min_{x \in \mathbb{R}^n} f(x) . \] Here, \(f \in \mathcal{C}^1\) is a convex, $L$-Lipschitz smooth function. Obviously we can solve this problem by using first-order methods, the question is how fast they are.</description>
    </item>
    <item>
      <title>About Me</title>
      <link>https://unionpan.github.io/about/</link>
      <pubDate>Sun, 26 Apr 2020 20:18:54 +0300</pubDate>
      <guid>https://unionpan.github.io/about/</guid>
      <description>I am a PhD candidate at NYU Tandon. My primary interest lies in statistical/reinforcement learning and applied game theory. Recently I&amp;rsquo;ve been working on macroscopic traffic assignment problems and Non-equilibrium learning in games.&#xA;I love basketball and boxing, I play mildly competitive games of basketball and do some sparring occasionally, you can also find me doing other outdoorsy stuff (like slacklining :))&#xA;I&amp;rsquo;ve recently just finished East of Eden, now I&amp;rsquo;m on my way reading Aumulet, Woes of the True Policeman, (still revisiting the key to 2666) and revisiting Gatsby.</description>
    </item>
  </channel>
</rss>
