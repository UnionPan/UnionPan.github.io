
<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <title>Reinforcement Learning with Human Feedback | union&#39;s blog</title>
    <meta name="description"
        content="I would love to think of the ICML 2023 conference in Honolulu as a pivotal event for my P.h.D. research. During that time I was kind of talking to Reagan and having the time of my life. I remember in the conference there was a workshop session named sampling over discrete space. It felt serendipitous, like the universe was pointing me toward somewhere significant, much like how my brilliant colleague Tao pointing to the bright future here haha">
    <meta name="google-site-verification" content="leqKZ6ZyQGOq6f_hMMWU-dgFPt8qgZeyJj-ZfCjyz3I" />
    <link rel="canonical" href="https://unionpan.github.io/post/2025/rlhf/" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.4/css/bulma.min.css">
    
    <link rel="stylesheet" href="https://unionpan.github.io/scss/style.min.bdfc41214cc1a8cd1b66e75ea61094e5fc36501e8aa0c63d2662d1a318cc3668.css">
    <meta property="og:url" content="https://unionpan.github.io/post/2025/rlhf/">
  <meta property="og:site_name" content="union&#39;s blog">
  <meta property="og:title" content="Reinforcement Learning with Human Feedback">
  <meta property="og:description" content="I would love to think of the ICML 2023 conference in Honolulu as a pivotal event for my P.h.D. research. During that time I was kind of talking to Reagan and having the time of my life. I remember in the conference there was a workshop session named sampling over discrete space. It felt serendipitous, like the universe was pointing me toward somewhere significant, much like how my brilliant colleague Tao pointing to the bright future here haha">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2025-08-25T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-08-25T00:00:00+00:00">

    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Reinforcement Learning with Human Feedback">
  <meta name="twitter:description" content="I would love to think of the ICML 2023 conference in Honolulu as a pivotal event for my P.h.D. research. During that time I was kind of talking to Reagan and having the time of my life. I remember in the conference there was a workshop session named sampling over discrete space. It felt serendipitous, like the universe was pointing me toward somewhere significant, much like how my brilliant colleague Tao pointing to the bright future here haha">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"
    integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"
    integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8"
    crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-P8CZD2GL8F"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-P8CZD2GL8F');
    </script>
    
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Person",
  "name": "Yunian Pan",
  "url": "https://unionpan.github.io",
  "sameAs": [
    "https://www.linkedin.com/in/unionpan/",
    "https://github.com/UnionPan"
  ]
}
</script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                delimiters: [
                    { left: "$$", right: "$$", display: true },
                    { left: "$", right: "$", display: false }
                ]
            });
        });
    </script>
    
</head><body>
        <div class="theme-toggle-container">
            <a id="theme-toggle" class="theme-toggle" href="#">
                <img src="https://unionpan.github.io/svg/sun.svg" alt="sun icon" class="theme-icon" />
            </a>
        </div>
        
        
        <button class="mobile-menu-toggle" id="mobile-menu-toggle" aria-label="Toggle menu">
            <span class="hamburger-line"></span>
            <span class="hamburger-line"></span>
            <span class="hamburger-line"></span>
        </button>

        <div class="layout-container">
            <aside class="sidebar" id="sidebar">
                <div class="sidebar-content">
                    <div class="sidebar-header">
                        <h1 class="site-title">
                            <a href="/" class="site-title-link">YUNIAN PAN</a>
                        </h1>
                    </div>
                    <nav class="sidebar-nav">
                        <div class="nav-item-container">
                            <a href="#" class="nav-link blog-toggle active" onclick="toggleBlogMenu(event)">
                                Blog <span class="dropdown-arrow">▼</span>
                            </a>
                            <div class="submenu" id="blog-submenu">
                                <a href="/post/about_me" class="submenu-link">About Me</a>
                                <a href="/post/2022" class="submenu-link">2022</a>
                                <a href="/post/2023" class="submenu-link">2023</a>
                                <a href="/post/2024" class="submenu-link">2024</a>
                                <a href="/post/2025" class="submenu-link">2025</a>
                            </div>
                        </div>
                        <a href="/statement" class="nav-link ">Statement/CV</a>
                        <a href="/contact" class="nav-link ">Contact</a>
                        <a href="/photos" class="nav-link ">Photos</a>
                    </nav>
                    <div class="sidebar-footer">
                        <div class="copyright">
                            © 2022-2025 all rights reserved
                        </div>
                        <div class="social-icons">
                            
                            <a href="https://www.linkedin.com/in/unionpan/" title="Linkedin" class="social-link">
                                <svg height="32px" width="32px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
    <rect x="2" y="9" width="4" height="12"></rect>
    <circle cx="4" cy="4" r="2"></circle>
</svg>
                            </a>
                            
                            <a href="https://github.com/UnionPan" title="Github" class="social-link">
                                <svg height="32px" width="32px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
                            </a>
                            
                            <a href="https://twitter.com/Union54572322" title="twitter" class="social-link">
                                <svg height="32px" width="32px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z">
    </path>
</svg>
                            </a>
                            
                            <a href="https://www.facebook.com/yunian.pan/" title="Facebook" class="social-link">
                                <svg height="32px" width="32px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path>
</svg>
                            </a>
                            
                            <a href="https://www.instagram.com/pyn_rodcutter/?hl=en" title="instagram" class="social-link">
                                <svg height="32px" width="32px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <rect x="2" y="2" width="20" height="20" rx="5" ry="5"></rect>
    <path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z"></path>
    <line x1="17.5" y1="6.5" x2="17.5" y2="6.5"></line>
</svg>
                            </a>
                            
                        </div>
                    </div>
                </div>
            </aside>
            <main class="main-content">
<div class="single-container">
    <div class="archive">
        
        <div class="post-thumbnail-container">
            <img src="https://unionpan.github.io//images/post/2025/RLHF/thumbnail.webp" alt="Reinforcement Learning with Human Feedback" class="post-thumbnail-image">
        </div>
        
        <h1 class="title is-1">Reinforcement Learning with Human Feedback</h1>
        <hr class="title-content-separator">
        
        <div class="title subtitle heading is-6">
            <div class="small-categories-container">
                
                        <span class="category-text">I haven&#39;t even tried Hugging Face a lot</span>
                    
            </div>
        </div>
        
        <div class="content article-content">
            <div class="toc-container">
                
    <div class="post-toc">
        
            <aside>
                <button id="tocButton" ><h4 id="contents" style="margin-left: 1vw;color:rgb(96, 134, 180);margin-bottom: 0;">CONTENTS</h4></button>
                <div id="hide"><nav id="TableOfContents">
  <ul>
    <li><a href="#rlhf-fundamentals">RLHF fundamentals</a>
      <ul>
        <li><a href="#why-alignment">Why Alignment?</a></li>
        <li><a href="#what-is-rlhf">What is RLHF?</a></li>
        <li><a href="#nash-learning-from-human-feedback-nlhf">Nash Learning from Human Feedback (NLHF)</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </aside>
        
    </div><script>
    
        let button = document.getElementById('tocButton');
        let hide = document.getElementById("hide");
        let contents=document.getElementById("contents");
        button.addEventListener("click", function() {
        if (hide.style.display!='block') {
            hide.style.display='block'
        } else {
            hide.style.display='none'
            contents.style.color='rgb(96, 134, 180)'
        }
        });
    




</script>
            </div>
            <p>I would love to think of the ICML 2023 conference in Honolulu as a pivotal event for my P.h.D. research. During that time I was kind of talking to Reagan and having the time of my life. I remember in the conference there was a workshop session named <em>sampling over discrete space</em>. It felt serendipitous, like the universe was pointing me toward somewhere significant, much like how my brilliant colleague <a href="https://taoli-nyu.github.io/">Tao</a> pointing to the bright future here haha</p>
<p><img src="/images/gallery/GPTempDownload.JPG" alt=""></p>
<p>The session ultimately was about how to use the massive structural discrete data, which has been major interests of many companies such as Google. The reason behind this was the killer success story of ChatGPT, which endorsed a bunch of subroutines such as SFT and RLHF (reinforcement learning with human feedback)
Back to school I told my advisor I wanted to write a paper about leveraging preference user data to improve user satisfaction and how significant the theoretical contribution could be. His immediate reaction was &lsquo;&lsquo;you do not have the data, and those companies will do astronomically better than you&rsquo;&rsquo;, no shit bro.</p>
<h2 id="rlhf-fundamentals">RLHF fundamentals</h2>
<h3 id="why-alignment">Why Alignment?</h3>
<p>Alignment is all about ensuring that LLMs behave the way <em>you</em> want. Think of Asimov’s Three Laws of Robotics, only instead of robots, we’re taming text generators.
Sometimes you want the model to obey. Other times, to be creative.  And often, to just <em>not hallucinate</em>.</p>
<hr>
<h3 id="what-is-rlhf">What is RLHF?</h3>
<p>RLHF happens in <strong>three acts</strong>:</p>
<ol>
<li>
<p><strong>Supervised Fine-Tuning (SFT):</strong><br>
Train the model on quality prompt–response pairs ${ (x^{(i)}, y^{*(i)}) }_{i=1}^N $. Maximize:<br>
$$
\log p_\theta( y_t^{*} | y_{ &lt;t }^{*}, x )
$$</p>
</li>
<li>
<p><strong>Reward Model Training:</strong><br>
Build a reward model $r_\phi(x, y) $ that learns what humans prefer by ranking outputs. You use pairwise data like:<br>
$$
D_{\text{pref}} = {(x, y_A, y_B, \text{pref}_{AB})}
$$</p>
</li>
<li>
<p><strong>Policy Optimization (usually PPO):</strong><br>
Use RL (e.g., Proximal Policy Optimization) to update the model:<br>
$$
\max_{\pi_\theta} \mathbb{E}[r_\phi(x, y)] - \lambda D_{\text{KL}}(\pi_\theta | \pi_{\text{ref}})
$$</p>
</li>
</ol>
<p>Basically, before you use RL as an End-to-End method to obtain a good generation policy, you want to prepare a reward model for it, from all the discrete preference data, you got two options oftentimes:</p>
<ul>
<li>
<p><strong>Bradley–Terry (BT) Model:</strong> This models binary preference:<br>
$$
\Pr(y_A \succ y_B | x) = \frac{\exp(r_\phi(x, y_A))}{\exp(r_\phi(x, y_A)) + \exp(r_\phi(x, y_B))}
$$</p>
</li>
<li>
<p><strong>Plackett–Luce (PL) Model:</strong> This generalizes to full rankings.</p>
</li>
</ul>
<p>But here’s the thing—reward models can be wrong. And LLMs are great at <em>gaming the reward</em> (a.k.a. reward hacking).</p>
<ul>
<li>
<p><strong>Reward Model Misalignment</strong>:<br>
Your $ r_\phi $ may not match your <em>actual</em> preferences.</p>
</li>
<li>
<p><strong>Covariate Shift</strong>:<br>
The policy drifts, and $r_\phi$ hasn’t seen those new outputs.</p>
</li>
<li>
<p><strong>Sample Inefficiency</strong>:<br>
PPO takes forever and a lot of annotations.</p>
</li>
</ul>
<p>You can skip the reward model. Go straight for the preferences. DPO directly optimizes:
$$
L_{\text{DPO}}(\theta) = - \sum_{(x, y^+, y^-)} \log \sigma\left(\beta \left[ \log \pi_\theta(y^+|x) - \log \pi_\theta(y^-|x) \right] \right)
$$</p>
<p>Where $\sigma(z) = \frac{1}{1 + e^{-z}} $.
DPO is not RL, not at all, but you may interpret $ \log \pi_\theta(y | x) $ as a <strong>latent reward</strong>:<br>
$$
r_\theta(x, y) := \log \pi_\theta(y | x),
$$
and that is where people started to use title &ldquo;your xxx is a latent xxx&rdquo; for some academic bullshit. Yeah, my PhD life is actually a huge waste of my life but I had no better things to do with it anyways.</p>
<h3 id="nash-learning-from-human-feedback-nlhf">Nash Learning from Human Feedback (NLHF)</h3>
<p>Apparently having a preference moodel you also go game-theoretic. In NLHF, we don’t just want a good policy—we want a <strong>Nash equilibrium</strong> in the space of preferences. This Nash equilibrium defines a strategy that cannot be beaten by an &lsquo;&lsquo;alternative self&rsquo;&rsquo;.</p>
<p>We define:</p>
<ul>
<li>A preference model $P(y \succ y&rsquo; | x) \in [0, 1] $</li>
<li>Policy preference:<br>
$$
P(\pi \succ \pi&rsquo;) = \mathbb{E}_{x,y,y&rsquo;}[P(y \succ y&rsquo; | x)]
$$</li>
<li>Goal: find $ \pi^* $ such that:<br>
$$
P(\pi^* \succ \pi&rsquo;) \geq \frac{1}{2}, \quad \forall \pi&rsquo;
$$</li>
</ul>
<p>This can be solved with Mirror Descent or Policy Gradients:
$$
\pi_{n+1} = \arg\max_\pi \langle \nabla J(\pi_n, \pi_n&rsquo;), \pi - \pi_n \rangle - \frac{1}{\eta} D_{\text{KL}}(\pi | \pi_n).
$$
Games like this is notoriously solvable via No-Regret methods, so you can come up with all kind of statistical bounds that ultimately boilds down to $\mathcal{O}(\sqrt{T})$ (or maybe a little different), or play with the reward/training structure a little bit more to come up with more fancy algorithms, and test them on some Hugging Face datasets.</p>
<p>Evaluations on tasks like TL;DR summarization show that:</p>
<ul>
<li><strong>NLHF beats RLHF</strong> in win-rate by ~5%</li>
<li>Using <strong>direct preference models</strong> improves ranking accuracy:
<ul>
<li>Gemma-2B: 74.2% → 80.7%</li>
<li>LLaMA3-8B: 87.8% → 94.8%</li>
</ul>
</li>
</ul>
<p>And… maybe it converges with fewer samples.</p>
<p>We are going to come back to this with a discussion of whether RLHF is actually useful.
Now it&rsquo;s the fall of 2025 and I already find myself so naive to wanted to do LLM alignment by myself, the resource and the effort put into this would have overwhelmed me, no doubt. A bigger question is, out of so many papers sprang in the last few years, what values can individual researchers actually create?</p>

        </div>
    </div>
    <a href="#" id="scrollToTopButton">
        <svg t="1686753152588" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg"
            p-id="3988" width="48" height="48">
            <path
                d="M518.5 360.3c-3.2-4.4-9.7-4.4-12.9 0l-178 246c-3.8 5.3 0 12.7 6.5 12.7H381c10.2 0 19.9-4.9 25.9-13.2L512 460.4l105.2 145.4c6 8.3 15.6 13.2 25.9 13.2H690c6.5 0 10.3-7.4 6.5-12.7l-178-246z"
                p-id="3989" fill="#363636"></path>
            <path
                d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m0 820c-205.4 0-372-166.6-372-372s166.6-372 372-372 372 166.6 372 372-166.6 372-372 372z"
                p-id="3990" fill="#363636"></path>
        </svg>
    </a><hr style="border-top: 1px solid #EEEEEE;">
<div id="comment"></div>
<script>
    const getStoredTheme = () => localStorage.getItem("theme") === "dark" ? "dark" : "light";

    const setGiscusTheme = () => {
        const sendMessage = (message) => {
            const iframe = document.querySelector('iframe.giscus-frame');
            if (iframe) {
                iframe.contentWindow.postMessage({giscus: message}, 'https://giscus.app');
            }
        }
        sendMessage({setConfig: {theme: getStoredTheme()}})
    }

    document.addEventListener("DOMContentLoaded", () => {
        const giscusAttributes = {
            "src": "https://giscus.app/client.js",
            "data-repo": "UnionPan\/UnionPan.github.io",
            "data-repo-id": "R_kgDOIZ-Mxw",
            "data-category": "General",
            "data-category-id": "DIC_kwDOIZ-Mx84CuT-c",
            "data-mapping": "pathname",
            "data-reactions-enabled": "1",
            "data-emit-metadata": "0",
            "data-input-position": "bottom",
            "data-theme": getStoredTheme(),
            "data-lang": "en",
            "data-loading": "lazy",
            "crossorigin": "anonymous",
        };

        
        const giscusScript = document.createElement("script");
        Object.entries(giscusAttributes).forEach(
            ([key, value]) => giscusScript.setAttribute(key, value));
        document.getElementById("comment").appendChild(giscusScript);

        
        const themeToggle = document.querySelector(".theme-toggle");
        if (themeToggle) {
            themeToggle.addEventListener("click", setGiscusTheme);
        }
    });

</script>


<div class="pp-container">
        <section class="pre-and-post">
            <div class="has-text-left">
                
                <p>Previous post</p>
                <a href="https://unionpan.github.io/post/2025/mechanism_design/">Bayesian Holonic (Global) Games</a>
                
            </div>
            <div class="has-text-right">
                
            </div>
        </section>
    </div>

</div>

                <footer class="footer">
</footer>
            </main>
        </div>

        <script>
            
            function setTheme(theme) {
                let body = document.body;
                let themeIcon = document.querySelector(".theme-icon");
                if (theme === "dark") {
                    body.classList.add("dark-mode");
                    themeIcon.src = "https:\/\/unionpan.github.io\/svg/moon.svg";
                    themeIcon.alt = "moon icon";
                } else {
                    body.classList.remove("dark-mode");
                    themeIcon.src = "https:\/\/unionpan.github.io\/svg/sun.svg";
                    themeIcon.alt = "sun icon";
                }
                localStorage.setItem("theme", theme);
            }

            
            document.addEventListener('DOMContentLoaded', function() {
                
                let theme = localStorage.getItem("theme");
                
                
                if (!theme) {
                    theme = 'dark';
                }
                
                setTheme(theme);

                
                document.getElementById("theme-toggle").addEventListener("click", function(e) {
                    e.preventDefault();
                    let currentTheme = localStorage.getItem("theme") || "light";
                    let newTheme = currentTheme === "light" ? "dark" : "light";
                    setTheme(newTheme);
                });
            });
            
            
            document.getElementById('mobile-menu-toggle').addEventListener('click', function() {
                const sidebar = document.getElementById('sidebar');
                const button = this;
                
                sidebar.classList.toggle('open');
                button.classList.toggle('active');
            });

            
            function toggleBlogMenu(event) {
                event.preventDefault();
                event.stopPropagation(); 
                const submenu = document.getElementById('blog-submenu');
                const arrow = document.querySelector('.dropdown-arrow');
                
                if (submenu.classList.contains('open')) {
                    submenu.classList.remove('open');
                    arrow.style.transform = 'rotate(0deg)';
                } else {
                    submenu.classList.add('open');
                    arrow.style.transform = 'rotate(180deg)';
                }
            }
            
            
            document.addEventListener('click', function(event) {
                const navContainer = document.querySelector('.nav-item-container');
                const submenu = document.getElementById('blog-submenu');
                const arrow = document.querySelector('.dropdown-arrow');
                
                if (!navContainer.contains(event.target) && submenu.classList.contains('open')) {
                    submenu.classList.remove('open');
                    arrow.style.transform = 'rotate(0deg)';
                }
            });

            
            document.addEventListener('click', function(event) {
                const sidebar = document.getElementById('sidebar');
                const toggleButton = document.getElementById('mobile-menu-toggle');
                
                if (sidebar.classList.contains('open') && 
                    !sidebar.contains(event.target) && 
                    !toggleButton.contains(event.target)) {
                    sidebar.classList.remove('open');
                    toggleButton.classList.remove('active');
                }
            });

            
            document.querySelectorAll('.sidebar .nav-link, .sidebar .submenu-link').forEach(link => {
                if (!link.classList.contains('blog-toggle')) {
                    link.addEventListener('click', function() {
                        const sidebar = document.getElementById('sidebar');
                        const toggleButton = document.getElementById('mobile-menu-toggle');
                        sidebar.classList.remove('open');
                        toggleButton.classList.remove('active');
                    });
                }
            });

            
            function addWheelScrolling(selector) {
                const carousel = document.querySelector(selector);
                if (!carousel) return;

                
                const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
                const isMac = /Mac|iPhone|iPod|iPad/i.test(navigator.userAgent);
                
                carousel.addEventListener('wheel', function(e) {
                    
                    if (isMobile) {
                        return;
                    }
                    
                    
                    
                    const isTouchpad = isMac && (Math.abs(e.deltaX) > 0 || Math.abs(e.deltaY) < 50);
                    
                    
                    if (isTouchpad && Math.abs(e.deltaX) > Math.abs(e.deltaY)) {
                        
                        return;
                    }
                    
                    
                    if (!isTouchpad && Math.abs(e.deltaY) > Math.abs(e.deltaX)) {
                        e.preventDefault();
                        carousel.scrollLeft += e.deltaY * 2;
                    }
                });
            }
            
            
            addWheelScrolling('.posts-carousel');
            addWheelScrolling('.photos-carousel');
        </script>
    </body>
</html>

